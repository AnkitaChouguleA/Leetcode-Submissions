{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5e617ae-b1f5-4616-b206-9cbc360ac4cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import dense_rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(\"TopThreeSalaries\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99c6e0ab-c572-401d-ba03-8160b7dfd40e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sample Employee data\n",
    "employee_data = [\n",
    "    (1, 'Joe', 85000, 1),\n",
    "    (2, 'Henry', 80000, 2),\n",
    "    (3, 'Sam', 60000, 2),\n",
    "    (4, 'Max', 90000, 1),\n",
    "    (5, 'Janet', 69000, 1),\n",
    "    (6, 'Randy', 85000, 1),\n",
    "    (7, 'Will', 70000, 1)\n",
    "]\n",
    "employee_columns = ['id', 'name', 'salary', 'departmentId']\n",
    "\n",
    "employee_df = spark.createDataFrame(employee_data, employee_columns)\n",
    "\n",
    "display(employee_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88edff48-2cf0-456b-835e-e9cd35b485ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sample Department data\n",
    "department_data = [\n",
    "    (1, 'IT'),\n",
    "    (2, 'Sales')\n",
    "]\n",
    "department_columns = ['id', 'name']\n",
    "\n",
    "department_df = spark.createDataFrame(department_data, department_columns)\n",
    "\n",
    "display(department_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c253f33b-b1be-425c-8d3b-8e5e093b105d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "joined_df = employee_df.alias('e').join(department_df.alias('d'), employee_df.departmentId == department_df.id, 'inner')\n",
    "display(joined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0332c777-68c6-4350-a359-152ee8f164ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, dense_rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "ranked_df = joined_df.withColumn(\n",
    "    'denseRank', \n",
    "    dense_rank().over(\n",
    "        Window.partitionBy('departmentId').orderBy(joined_df.salary.desc())\n",
    "    )\n",
    ")\n",
    "#display(ranked_df)\n",
    "\n",
    "top_three_df = ranked_df.select(\n",
    "    col('d.name').alias('department'), \n",
    "    col('e.name').alias('employee'), \n",
    "    col('e.salary').alias('salary')\n",
    ").filter(col('denseRank') <= 3)\n",
    "display(top_three_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1a394f9-56c2-453a-81da-dbeb0bc86c52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "185. pyspark sln 2025-07-22 16_07_04",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
